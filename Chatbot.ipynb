{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBzMWv3qiV+fLwRQzvlSgY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anion-codes/Medical_chatbot/blob/main/Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_core langchain langchain-community pinecone-client==3.0.1 ctransformers==0.2.5 sentence-transformers pypdf==3.16.4 PyMuPDF==1.24.1 flask==2.3.3 transformers langchain_pinecone==0.2.6 pinecone-client==3.0.1"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9jcJyQ5IrNWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5s6cIgmlp1Iw"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import unicodedata\n",
        "from uuid import uuid4\n",
        "from google.colab import drive, userdata\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.documents import Document\n",
        "from langchain.chains import RetrievalQA, StuffDocumentsChain, LLMChain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n",
        "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain_community.llms import CTransformers\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from pinecone import Pinecone\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper Functions\n",
        "def remove_line_breaks(text):\n",
        "    return re.sub(r'\\n+', ' ', text)\n",
        "\n",
        "def remove_extra_spaces(text):\n",
        "    return re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "def fix_hyphenated_linebreaks(text):\n",
        "    return re.sub(r'-\\n', '', text)\n",
        "\n",
        "def normalize_unicode(text):\n",
        "    return unicodedata.normalize('NFKC', text)\n",
        "\n",
        "def remove_non_ascii(text):\n",
        "    return re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
        "\n",
        "def remove_urls(text):\n",
        "    return re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
        "\n",
        "def remove_emails(text):\n",
        "    return re.sub(r'\\S+@\\S+', '', text)\n",
        "\n",
        "def remove_special_chars(text):\n",
        "    return re.sub(r'[^\\w\\s.,;:!?()\\-]', '', text)\n",
        "\n",
        "def remove_broken_sentences(text):\n",
        "    return \"\\n\".join([line for line in text.splitlines() if re.search(r'[aeiouAEIOU]', line)])\n",
        "\n",
        "def merge_short_lines(text, min_length=40):\n",
        "    lines = text.splitlines()\n",
        "    merged, buffer = [], ''\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if len(line) < min_length:\n",
        "            buffer += ' ' + line\n",
        "        else:\n",
        "            merged.append(buffer.strip())\n",
        "            buffer = line\n",
        "    merged.append(buffer.strip())\n",
        "    return '\\n'.join([line for line in merged if line])\n",
        "\n",
        "def clean_text(text):\n",
        "    text = normalize_unicode(text)\n",
        "    text = fix_hyphenated_linebreaks(text)\n",
        "    text = remove_line_breaks(text)\n",
        "    text = remove_urls(text)\n",
        "    text = remove_emails(text)\n",
        "    text = remove_special_chars(text)\n",
        "    text = remove_non_ascii(text)\n",
        "    text = remove_broken_sentences(text)\n",
        "    text = merge_short_lines(text)\n",
        "    text = remove_extra_spaces(text)\n",
        "    return text\n",
        "# add and remove functions if there is over-cleaaning problem\n",
        "\n",
        "def text_split(documents):\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=500, chunk_overlap=20,\n",
        "    )\n",
        "    return splitter.split_documents(documents)\n",
        "\n"
      ],
      "metadata": {
        "id": "i0zfpsD6rHAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "id": "EJbQo2Xip-TL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and Clean PDFs\n",
        "pdf_dir = '/content/drive/MyDrive/docs/'\n",
        "loader = DirectoryLoader(pdf_dir, loader_cls=PyPDFLoader)\n",
        "documents = loader.load()\n",
        "\n",
        "cleaned_documents = [Document(page_content=doc.page_content) for doc in documents] #add clean text like page_content=clean_text(doc.page_content)\n",
        "text_chunks = text_split(cleaned_documents)\n",
        "print(f\"Number of text chunks: {len(text_chunks)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "tEvN_ZPlqEcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Embeddings\n",
        "embedding_model = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n"
      ],
      "metadata": {
        "id": "FLIQ0RuvqIZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pinecone Setup\n",
        "API_key = userdata.get('PINECONE_API_KEY')\n",
        "pc = Pinecone(api_key=API_key)\n",
        "index_name = f\"chatbot-{str(uuid4())[:8]}\" #TO GENERATE NEW INDEX EVERYTIME\n",
        "\n",
        "pc.create_index_for_model(\n",
        "    name=index_name,\n",
        "    cloud=\"aws\",\n",
        "    region=\"us-east-1\",\n",
        "    embed={\"model\": \"llama-text-embed-v2\", \"field_map\": {\"text\": \"chunk_text\"}}\n",
        ")\n",
        "\n",
        "index = pc.Index(index_name)\n",
        "vector_store = PineconeVectorStore(index=index, embedding=embedding_model)\n",
        "\n"
      ],
      "metadata": {
        "id": "LYrKNBh0qMNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add documents\n",
        "uuids = [str(uuid4()) for _ in text_chunks]\n",
        "text_contents = [chunk.page_content for chunk in text_chunks]\n",
        "vector_store.add_texts(texts=text_contents, ids=uuids)\n",
        "\n"
      ],
      "metadata": {
        "id": "5mWqU3IVqRcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieval and LLM Setup\n",
        "retriever = vector_store.as_retriever(similarity_top_k=3)\n",
        "\n",
        "llm = CTransformers(\n",
        "    model=\"/content/drive/MyDrive/docs/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
        "    model_type=\"llama\",\n",
        "    config={\"max_new_tokens\": 512, \"temperature\": 0.8}\n",
        ")\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    Use the following pieces of information to answer the user's question.\n",
        "    If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "\n",
        "    Context: {context}\n",
        "    Question: {question}\n",
        "\n",
        "    Only return the helpful answer below and nothing else.\n",
        "    Helpful answer:\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "document_chain = StuffDocumentsChain(\n",
        "    llm_chain=LLMChain(llm=llm, prompt=prompt),\n",
        "    document_variable_name=\"context\"\n",
        ")\n",
        "\n",
        "qa = RetrievalQA(\n",
        "    retriever=retriever,\n",
        "    combine_documents_chain=document_chain,\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "ckPH85_fqUH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testruning QA based on a medical book\n",
        "query = \"what is allergy\"\n",
        "docs = retriever.get_relevant_documents(query)\n",
        "print(\"Retrieved Docs:\", docs)\n",
        "response = qa.invoke(query)\n",
        "print(\"Answer:\", response['result'])"
      ],
      "metadata": {
        "id": "QjnloyvgqYpC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}